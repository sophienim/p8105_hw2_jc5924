p8105_hw2_jc5924
================

# Problem 1

### NYC Transit data

``` r
transit_data=
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(entry=recode(entry,"YES"="TRUE","NO"="FALSE"))
         
transit_data
```

    ## # A tibble: 1,868 × 19
    ##    line     station_name station_latitude station_longitude route1 route2 route3
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  7 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  8 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  9 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## 10 4 Avenue 53rd St                  40.6             -74.0 R      <NA>   <NA>  
    ## # … with 1,858 more rows, and 12 more variables: route4 <chr>, route5 <chr>,
    ## #   route6 <chr>, route7 <chr>, route8 <chr>, route9 <chr>, route10 <chr>,
    ## #   route11 <chr>, entrance_type <chr>, entry <chr>, vending <chr>, ada <lgl>

### Explaining the dataset

-   The dataset contains 19 variables which are line, station_name,
    station_latitude, station_longitude, route1, route2, route3, route4,
    route5, route6, route7, route8, route9, route10, route11,
    entrance_type, entry, vending, ada and the demension of this dataset
    is 1868 rows \* 19 columns. I believe these data is not fairly tidy
    that after importing the file, we only clean the variable names to
    turn those into lower case with under dash connected, and we select
    the needed columns for this dataset. Lastly, we convert the entry
    variable from a character variable to a logical variable.

### Answering questions

-   There are 465 distinct stations.
-   There are

``` r
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

stations that are ADA compliant.

-   The proportion of station entrances/exits without vending allow
    entrance is

``` r
transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## Warning in mean.default(.): argument is not numeric or logical: returning NA

    ## [1] NA

### Reformatting route name and route number

``` r
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

# Problem 2

### Read and clean Mr.Trash Wheel data

``` r
mrtrashwheel_data=
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx",
                     sheet= "Mr. Trash Wheel",
                     range="A2:N549") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    wheel_name = "Mr. Trash Wheel",
    year=as.numeric(year))
mrtrashwheel_data     
```

    ## # A tibble: 547 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # … with 537 more rows, and 9 more variables: plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>, wheel_name <chr>

### Read and clean Professor Trash Wheel data

``` r
proftrashwheel_data = 
  readxl::read_excel("./data/Trash Wheel Collection Data.xlsx",
                     sheet= "Professor Trash Wheel",
                     range="A2:M96") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = NA,
         wheel_name = "Professor Trash Wheel")
proftrashwheel_data
```

    ## # A tibble: 94 × 15
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # … with 84 more rows, and 9 more variables: plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, homes_powered <dbl>,
    ## #   sports_balls <lgl>, wheel_name <chr>

### Combining the two sheets

``` r
combinedtrashwheel_data=
  full_join(mrtrashwheel_data,proftrashwheel_data) %>% 
   janitor::clean_names()
```

    ## Joining, by = c("dumpster", "month", "year", "date", "weight_tons",
    ## "volume_cubic_yards", "plastic_bottles", "polystyrene", "cigarette_butts",
    ## "glass_bottles", "grocery_bags", "chip_bags", "sports_balls", "homes_powered",
    ## "wheel_name")

``` r
combinedtrashwheel_data
```

    ## # A tibble: 641 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # … with 631 more rows, and 9 more variables: plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>, wheel_name <chr>

### A paragraph about the data

-   The above dataset is the two sheets combined together and there are
    total of 641 observations and 15 varibles in the combined dataset.
    Some variables are essential to notice that are weights of plastics,
    sports_balls, glass and trash bottle being collected over the years.
    We can select and filter the dataset and compare and contrast
    between Mr.Trash Wheel data and Professor Trash Wheel data.
-   The total weight of trash collected by Professor Trash Wheel is
    190.12 tons.
-   The total number of sports balls collected by Mr. Trash Wheel in
    2020 is 856.

# Problem 3

### Clean pols-month data

``` r
pols_data=
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>%
  separate(mon, c("year", "month", "day")) %>% 
  mutate(
    month=month.name[as.numeric(month)],
    year=as.integer(year),
    president=case_when(prez_dem==1~"dem",
                        prez_gop==1&2~"gop")) %>% 
  select(-prez_dem,-prez_gop,-day) %>% 
  arrange(year, month)
pols_data
```

    ## # A tibble: 822 × 9
    ##     year month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 April         23      51     253      23      45     198 dem      
    ##  2  1947 August        23      51     253      23      45     198 dem      
    ##  3  1947 December      24      51     253      23      45     198 dem      
    ##  4  1947 February      23      51     253      23      45     198 dem      
    ##  5  1947 January       23      51     253      23      45     198 dem      
    ##  6  1947 July          23      51     253      23      45     198 dem      
    ##  7  1947 June          23      51     253      23      45     198 dem      
    ##  8  1947 March         23      51     253      23      45     198 dem      
    ##  9  1947 May           23      51     253      23      45     198 dem      
    ## 10  1947 November      24      51     253      23      45     198 dem      
    ## # … with 812 more rows

### Clean snp data

``` r
snp_data=
  read_csv("./data/fivethirtyeight_datasets/snp.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>%
  separate(date,c("month", "day", "year")) %>%
  mutate(
    month = month.name[as.numeric(month)],
    year = as.numeric(year), 
    year = ifelse(year<16, year+2000, year+1900)) %>%
  select(year, month, everything()) %>% 
  select(-day) %>% 
  arrange(year, month)
snp_data        
```

    ## # A tibble: 787 × 3
    ##     year month    close
    ##    <dbl> <chr>    <dbl>
    ##  1  1950 April     18.0
    ##  2  1950 August    18.4
    ##  3  1950 December  20.4
    ##  4  1950 February  17.2
    ##  5  1950 January   17.0
    ##  6  1950 July      17.8
    ##  7  1950 June      17.7
    ##  8  1950 March     17.3
    ##  9  1950 May       18.8
    ## 10  1950 November  19.5
    ## # … with 777 more rows

### Tidy the unemployment data

``` r
unemployment_data=
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to="month",
    values_to="unemployment%") %>%
  mutate(
    month = recode(month, "jan" = "January", "feb" = "February", "mar" = "March", "apr" = "April", "may" = "May", "jun" = "June",  "jul" = "July", "aug" = "August", "sep" = "September", "oct" = "October", "nov" = "November", "dec" = "December" ),
    year=as.numeric(year)) %>%
  arrange(year, month) 
unemployment_data
```

    ## # A tibble: 816 × 3
    ##     year month    `unemployment%`
    ##    <dbl> <chr>              <dbl>
    ##  1  1948 April                3.9
    ##  2  1948 August               3.9
    ##  3  1948 December             4  
    ##  4  1948 February             3.8
    ##  5  1948 January              3.4
    ##  6  1948 July                 3.6
    ##  7  1948 June                 3.6
    ##  8  1948 March                4  
    ##  9  1948 May                  3.5
    ## 10  1948 November             3.8
    ## # … with 806 more rows

### Join the datasets by merging

``` r
join_dataset=
  left_join(pols_data,snp_data,by=c("year","month")) %>% 
  left_join(unemployment_data,by=c("year","month"))
join_dataset
```

    ## # A tibble: 822 × 11
    ##     year month   gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 April        23      51     253      23      45     198 dem          NA
    ##  2  1947 August       23      51     253      23      45     198 dem          NA
    ##  3  1947 Decemb…      24      51     253      23      45     198 dem          NA
    ##  4  1947 Februa…      23      51     253      23      45     198 dem          NA
    ##  5  1947 January      23      51     253      23      45     198 dem          NA
    ##  6  1947 July         23      51     253      23      45     198 dem          NA
    ##  7  1947 June         23      51     253      23      45     198 dem          NA
    ##  8  1947 March        23      51     253      23      45     198 dem          NA
    ##  9  1947 May          23      51     253      23      45     198 dem          NA
    ## 10  1947 Novemb…      24      51     253      23      45     198 dem          NA
    ## # … with 812 more rows, and 1 more variable: `unemployment%` <dbl>

### Short paragraph about datasets

-   There are 822 observations and 9 variables in the `pols_month`
    dataset. The essential variables are year, month, gov_gop, sen_gop,
    rep_gop, gov_dem, sen_dem, rep_dem, president. The years went from
    1947 to 2015 of nominations for domacratics and republicans.

-   There are 787 observations and 3 variables in the `snp` dataset. The
    essential variables are year, month, close. The years went from 1950
    to 2015 for standard and poor stock market index number.

-   There are 816 observations and 3 variables in the `unemployment`
    dataset. The essential variables are year, month, unemployment%. The
    years went from 1948 to 2015 for unemployment rate.

-   There are 822 observations and 11 variables in the `join_dataset`.
    The essential variables are year, month, gov_gop, sen_gop, rep_gop,
    gov_dem, sen_dem, rep_dem, president, close, unemployment%. The
    years went from 1947 to 2015 for all the data combined.
